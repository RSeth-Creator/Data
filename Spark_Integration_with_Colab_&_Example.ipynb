{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark Integration with Colab & Example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMnzQ8qSPF5E",
        "outputId": "cf12bea4-2a08-4f72-bc6e-7dd65c90dc8d"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjUg5LQ7Qfdj",
        "outputId": "1c089791-da13-4de1-c530-6f7c0aada75a"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QiroTMCQhqp",
        "outputId": "343bb79c-e3b0-4e96-fbcb-113df92c52ae"
      },
      "source": [
        "#Download Spark from the Apache spark \r\n",
        "!wget https://mirrors.estointernet.in/apache/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-15 19:00:22--  https://mirrors.estointernet.in/apache/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
            "Resolving mirrors.estointernet.in (mirrors.estointernet.in)... 43.255.166.254, 2403:8940:3:1::f\n",
            "Connecting to mirrors.estointernet.in (mirrors.estointernet.in)|43.255.166.254|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 224374704 (214M) [application/octet-stream]\n",
            "Saving to: ‘spark-3.1.1-bin-hadoop2.7.tgz’\n",
            "\n",
            "spark-3.1.1-bin-had 100%[===================>] 213.98M  13.7MB/s    in 17s     \n",
            "\n",
            "2021-03-15 19:00:40 (12.6 MB/s) - ‘spark-3.1.1-bin-hadoop2.7.tgz’ saved [224374704/224374704]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEeVdRZkQxFb"
      },
      "source": [
        "#Extract .tgz file\r\n",
        "!tar -xvzf spark-3.1.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcn6fTloRIbr",
        "outputId": "7a330fb3-cc0d-44d9-e845-3dd9c4ce3d5b"
      },
      "source": [
        "#Find out the contents in the spark folder \r\n",
        "!ls /content/spark-3.1.1-bin-hadoop2.7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin   data\tjars\t    LICENSE   NOTICE  R\t\t RELEASE  yarn\n",
            "conf  examples\tkubernetes  licenses  python  README.md  sbin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP3yfI7BRaeQ",
        "outputId": "f856cfa7-59c4-4451-b5e1-9b24b3400451"
      },
      "source": [
        "#Installing Spark in google colab\r\n",
        "!pip install findspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting findspark\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/2d/2e39f9a023479ea798eed4351cd66f163ce61e00c717e03c37109f00c0f2/findspark-1.4.2-py2.py3-none-any.whl\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-1.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLCfa2jsRuVR"
      },
      "source": [
        "#Setting the SPARk_HOME \r\n",
        "import os\r\n",
        "os.environ[\"SPARK_HOME\"]=\"/content/spark-3.1.1-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpTZ_oR3R-wc"
      },
      "source": [
        "#Creating pyspark importable \r\n",
        "import findspark\r\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjo3MgCoST9_"
      },
      "source": [
        "import pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr1RBnCdS3Dp"
      },
      "source": [
        "#Creating the spark context by this we can create RDD\r\n",
        "from pyspark import SparkContext\r\n",
        "sc =SparkContext()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPDvTWdmS6rD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c522dd9b-83f3-460f-ad44-79bacea771a4"
      },
      "source": [
        "#Example to create RDD\r\n",
        "data=[1,2,3,4]\r\n",
        "rdd=sc.parallelize(data)\r\n",
        "rdd.count()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq7sbW2PTnlP"
      },
      "source": [
        "# Creating Spark Session which will  on top of Spark environment to run the spark code(data frame)\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "spark=SparkSession.builder.appName(\"GC\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM__sME3UN3e"
      },
      "source": [
        "#Update version of spark in which we can see the dataframe concept \r\n",
        "df=spark.read.csv(header=True,path='/content/sample_data/california_housing_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elof8G1BU0Cy",
        "outputId": "76416510-7f10-4225-bd9f-6334ff39d87b"
      },
      "source": [
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population|households|median_income|median_house_value|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|-122.050000|37.370000|         27.000000|3885.000000|    661.000000|1537.000000|606.000000|     6.608500|     344700.000000|\n",
            "|-118.300000|34.260000|         43.000000|1510.000000|    310.000000| 809.000000|277.000000|     3.599000|     176500.000000|\n",
            "|-117.810000|33.780000|         27.000000|3589.000000|    507.000000|1484.000000|495.000000|     5.793400|     270500.000000|\n",
            "|-118.360000|33.820000|         28.000000|  67.000000|     15.000000|  49.000000| 11.000000|     6.135900|     330000.000000|\n",
            "|-119.670000|36.330000|         19.000000|1241.000000|    244.000000| 850.000000|237.000000|     2.937500|      81700.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "zTJgVAAHWHoz",
        "outputId": "d4fd962c-ff9d-48a2-c30e-09f9ae3229ea"
      },
      "source": [
        "#ExternalRDD example \r\n",
        "p=sc.textFile('/content/sample_data/california_housing_test.csv')\r\n",
        "p.first()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2QAqrVZXQE6",
        "outputId": "dd7c1ae2-bbc0-4460-8253-a5db513f54f8"
      },
      "source": [
        "#Map function example \r\n",
        "nums = sc.parallelize([1, 2, 3, 4])\r\n",
        "squared = nums.map(lambda x: x * x).collect()\r\n",
        "for num in squared:\r\n",
        " print(num)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "4\n",
            "9\n",
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv1eM4ldXk9P",
        "outputId": "2e0993aa-533a-488f-d486-5f4577815efa"
      },
      "source": [
        "#Reduce function example\r\n",
        "sum = rdd.reduce(lambda x, y: x + y)\r\n",
        "print(um)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}