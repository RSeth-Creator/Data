{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_S2_TextPreprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpQbTBY0XJ716lvMRrbaor",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RSeth-Creator/Data/blob/dataScience/NLP_S2_TextPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAQXrG-h0DFh",
        "outputId": "2752e770-9ba8-4929-86d5-2d6d121c1ea5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXjoruQa1rmH"
      },
      "source": [
        "## **Data Cleaning/ Preprocessing **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3lGfJVd1DD_"
      },
      "source": [
        "Importing data from file & added column name "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dapptOvE0RPd",
        "outputId": "205f0c70-2d52-4e27-c69e-cbefff6a6162"
      },
      "source": [
        "#read the file using pandas \n",
        "import pandas as pd \n",
        "data = pd.read_csv(\"drive/My Drive/SMSSpamCollection.tsv\",sep = '\\t', header = None)\n",
        "data.columns = ['labels', 'body_text']\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>body_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  labels                                          body_text\n",
              "0    ham  I've been searching for the right words to tha...\n",
              "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "2    ham  Nah I don't think he goes to usf, he lives aro...\n",
              "3    ham  Even my brother is not like to speak with me. ...\n",
              "4    ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Yr3XenPm0U2Q",
        "outputId": "7099b793-2545-4b66-ca8e-1095efff82e4"
      },
      "source": [
        "import string \n",
        "# It will show the different kind of punctuation present\n",
        "string.punctuation "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZE8v0lD1MRQ"
      },
      "source": [
        "Create a function to remove the punctuation from the string "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p9oPLVh30XTb",
        "outputId": "5a2b0c60-6df3-4e65-84b8-dc6cb124efb2"
      },
      "source": [
        "# Create a function to remove punctuatiion from the dataframe \n",
        "def remove_punct(text):\n",
        "  text_nopunct = ''.join([char for char in text if char not in string.punctuation])\n",
        "  #''.join  will join the individual character after removing the punctuation\n",
        "  return text_nopunct\n",
        "\n",
        "data['body_text_nopunct']  = data['body_text'].apply(lambda x: remove_punct(x))\n",
        "#Applied the lambda function to whole body_text column\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_nopunct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to tha...</td>\n",
              "      <td>Ive been searching for the right words to than...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "      <td>Even my brother is not like to speak with me T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  labels  ...                                  body_text_nopunct\n",
              "0    ham  ...  Ive been searching for the right words to than...\n",
              "1   spam  ...  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "2    ham  ...  Nah I dont think he goes to usf he lives aroun...\n",
              "3    ham  ...  Even my brother is not like to speak with me T...\n",
              "4    ham  ...                  I HAVE A DATE ON SUNDAY WITH WILL\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASDeJSDd1Udx"
      },
      "source": [
        "Create a Function to tokenize the text "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3z4rZGX0YA5"
      },
      "source": [
        "import re "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXGkG1670aKw"
      },
      "source": [
        "def tokenize(text):\n",
        "  tokens = re.split('\\W+',text) # '\\W+' it will remove the special character and the blank spaces \n",
        "  return tokens\n",
        "\n",
        "data['body_text_tokens'] =data['body_text'].apply(lambda x: tokenize(x.lower()))\n",
        "# apply the tokenize function to all the rows in the dfataframe\n",
        "#x.lower() convert all the characters in the lower format "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ayrOk3A1ZRk"
      },
      "source": [
        "Create a function to remove the stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7EIkauC0dmZ",
        "outputId": "13122d7f-2b74-4292-fa3e-80aae1b3b739"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stopword = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OHbmsPb0fqQ"
      },
      "source": [
        "def remove_stopwords(tokenize_list):\n",
        "  text = [word for word in tokenize_list if word not in stopword]\n",
        "  return text\n",
        "data['body_text_tokens_wsw'] =data['body_text_tokens'].apply(lambda x: remove_stopwords(x))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfT0dXLv2MQH"
      },
      "source": [
        "Create a function for stemming (Chopped off the suffix from the word to find out the base word)\n",
        "\n",
        "> Based on NLTK\n",
        "\n",
        "1.   Porter Stemmer\n",
        "2.   Snowball Stemmer\n",
        "3.   Lancaster Stemmer\n",
        "4.   RegEx-Based Stemmer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqzNkXft16kd"
      },
      "source": [
        "import nltk\n",
        "from nltk import LancasterStemmer"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmTu-O2r3lUv"
      },
      "source": [
        "ps = nltk.PorterStemmer()\n",
        "ss = nltk.SnowballStemmer('english')\n",
        "ls = LancasterStemmer()\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDXHBf_b5jDS"
      },
      "source": [
        "#data['body_text_tokens_wsw']\n",
        "def stemming (tokenized_text):\n",
        "  text = [ps.stem(word) for word in tokenized_text ]\n",
        "  return text \n",
        "data['stem_tokens'] = data['body_text_tokens_wsw'].apply(lambda x:stemming(x) )"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lJObd6M72FS"
      },
      "source": [
        "Lemmatization  function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl3Yg1qT766c",
        "outputId": "95be5c8f-8ac8-4ed1-b096-fe4e644c3f20"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "wnl = nltk.WordNetLemmatizer()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJjJOcd-8jtK"
      },
      "source": [
        "#data['body_text_tokens_wsw']\n",
        "def lemma (tokenized_text):\n",
        "  text = [wnl.lemmatize(word) for word in tokenized_text ]\n",
        "  return text \n",
        "data['root_tokens'] = data['body_text_tokens_wsw'].apply(lambda x:lemma(x) )"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "s0zLQa6o9vvg",
        "outputId": "e68fd193-a7fd-43a6-9a58-243536d0c9f3"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_nopunct</th>\n",
              "      <th>body_text_tokens</th>\n",
              "      <th>body_text_tokens_wsw</th>\n",
              "      <th>stem_tokens</th>\n",
              "      <th>root_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to tha...</td>\n",
              "      <td>Ive been searching for the right words to than...</td>\n",
              "      <td>[i, ve, been, searching, for, the, right, word...</td>\n",
              "      <td>[searching, right, words, thank, breather, pro...</td>\n",
              "      <td>[search, right, word, thank, breather, promis,...</td>\n",
              "      <td>[searching, right, word, thank, breather, prom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
              "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
              "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
              "      <td>[nah, think, goe, usf, live, around, though]</td>\n",
              "      <td>[nah, think, go, usf, life, around, though]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "      <td>Even my brother is not like to speak with me T...</td>\n",
              "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
              "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
              "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
              "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
              "      <td>[i, have, a, date, on, sunday, with, will, ]</td>\n",
              "      <td>[date, sunday, ]</td>\n",
              "      <td>[date, sunday, ]</td>\n",
              "      <td>[date, sunday, ]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  labels  ...                                        root_tokens\n",
              "0    ham  ...  [searching, right, word, thank, breather, prom...\n",
              "1   spam  ...  [free, entry, 2, wkly, comp, win, fa, cup, fin...\n",
              "2    ham  ...        [nah, think, go, usf, life, around, though]\n",
              "3    ham  ...  [even, brother, like, speak, treat, like, aid,...\n",
              "4    ham  ...                                   [date, sunday, ]\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNYeLHtz5m4M"
      },
      "source": [
        "Example of three different stemming approach "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miLf-POc5swV"
      },
      "source": [
        "Porter Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZID9ILC3vD9",
        "outputId": "4188c4e0-c0f6-48de-f9a4-3cb22893a257"
      },
      "source": [
        "# Example how porter stemmer works in a word \n",
        "print(ps.stem('run'))\n",
        "print(ps.stem('running'))\n",
        "print(ps.stem('runner'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n",
            "run\n",
            "runner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xi7hyMi5vzs"
      },
      "source": [
        "Snowball Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjjhZ1S84frL",
        "outputId": "7acd9e91-08e4-41e1-dadf-7d167c97760e"
      },
      "source": [
        "# Example how Snowball stemmer works in a word \n",
        "print(ss.stem('run'))\n",
        "print(ss.stem('running'))\n",
        "print(ss.stem('runner'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n",
            "run\n",
            "runner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjwtl3bk5yO_"
      },
      "source": [
        "Lancaster stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgNKr9Wx320i",
        "outputId": "06eba868-0334-48a0-9596-12c9cd4bb147"
      },
      "source": [
        "# Example how lancaster stemmer works in a word \n",
        "print(ls.stem('run'))\n",
        "print(ls.stem('running'))\n",
        "print(ls.stem('runner'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n",
            "run\n",
            "run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtvPBx2w8rML"
      },
      "source": [
        "Example of lemmatizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I30vE2Dm7NH5",
        "outputId": "3766a8fd-155f-4fc9-f228-4aa2c78bfb51"
      },
      "source": [
        "print(wnl.lemmatize('meaness'))\n",
        "print(wnl.lemmatize('meaning'))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meaness\n",
            "meaning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC8bC6M580i7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}