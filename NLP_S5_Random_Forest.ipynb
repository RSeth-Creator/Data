{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_S5_Random_Forest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPsQh4fy+VSdc2Q/23Ft1RH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RSeth-Creator/Data/blob/dataScience/NLP_S5_Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZU_EFMRpP2q"
      },
      "source": [
        "\n",
        "Evaluation matrices \n",
        "1.   Accuracy = (Predicted Correctly)/(Total No. of Observation)\n",
        "2.   Precision = (Predicted spam that are actually spam)/(total predicted as spam)\n",
        "\n",
        "1.   Recall = (Predicted as spam that are actually spam)/(Total that are actually spam)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iVEV-cttFHR"
      },
      "source": [
        "Ensemble Techniques:\n",
        "\n",
        "1.   Techniques that creates multiple models and then combines them to provide better results than any of the single model individually\n",
        "2.   Aggregating the opinion of many rather than the isolated opinion of one \n",
        "\n",
        "\n",
        "1.   Random Forest : Ensemble learning method that constructts a collection of decision trees and the aggregates the predictions of each tree  to determine the final prediction. by the voting of the output list of all  the decesion tree we can predict the outcome . it can handle ordinal & continuous data  & can handle missing value & outlier, less likely to overfit\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXMPQNZd6V34",
        "outputId": "a61ed2ac-872b-4500-9129-22f4c5a6ad7d"
      },
      "source": [
        "#Mounting the drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0qfIyn98uBS"
      },
      "source": [
        "## IMport required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb0UzSv7sSxF",
        "outputId": "1ed20aaf-6512-4e6f-f225-00a2fa61d936"
      },
      "source": [
        "import nltk\n",
        "import pandas as pd \n",
        "import re \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import string \n",
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "ps=nltk.PorterStemmer()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sB1QZWS80Rb"
      },
      "source": [
        "## Import data from fil"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wPLVk_Ce7AZe",
        "outputId": "4e9fb687-8b20-46fe-9667-6caed3eb33a3"
      },
      "source": [
        "data = pd.read_csv(\"drive/My Drive/SMSSpamCollection.tsv\",sep = '\\t', header = None)\n",
        "data.columns = ['labels', 'body_text']\n",
        "data.head()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>body_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  labels                                          body_text\n",
              "0    ham  I've been searching for the right words to tha...\n",
              "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "2    ham  Nah I don't think he goes to usf, he lives aro...\n",
              "3    ham  Even my brother is not like to speak with me. ...\n",
              "4    ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8psA8PG-87r-"
      },
      "source": [
        "## Create new feature (Number od character present in the string)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8SK2qN97HUU"
      },
      "source": [
        "# length of character = len(string)- count of white-spaces\n",
        "data['body_len']=data['body_text'].apply(lambda x :len(x)-x.count(\" \"))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K51tnfxK9Hae"
      },
      "source": [
        "## Create new feature (% of punctuation present in the string)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "zbkSLMLC7LRa",
        "outputId": "7bd6dd7c-330c-433b-f739-957dc51fcefa"
      },
      "source": [
        "\n",
        "#Creating a function to fin dout the % of punctuation present in the text\n",
        "def count_punct(text):\n",
        "  count = sum([1 for char in text if char in string.punctuation])\n",
        "  return round(count/(len(text) - text.count(\" \")), 3)*100\n",
        "    \n",
        "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
        "\n",
        "data.head(2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_len</th>\n",
              "      <th>punct%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to tha...</td>\n",
              "      <td>160</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>128</td>\n",
              "      <td>4.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  labels                                          body_text  body_len  punct%\n",
              "0    ham  I've been searching for the right words to tha...       160     2.5\n",
              "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...       128     4.7"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovuq7bZk9XND"
      },
      "source": [
        "## Create a function to clean the text "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ3O8bao7NM-"
      },
      "source": [
        "def clean_text(text):\n",
        "  text = \"\".join([word.lower() for word in text if word not in string.punctuation])#Punctuation removal\n",
        "  tokens = re.split('\\W+', text) #tokenize\n",
        "  text = [ps.stem(word) for word in tokens if word not in stopwords] # Stopwords removal\n",
        "  return text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah9x8qjN9bvJ"
      },
      "source": [
        "## Apply the vectorizer in the text to find out the score "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oukKIqNq7Zb4"
      },
      "source": [
        "tfidf_vect  = TfidfVectorizer(analyzer=clean_text)\n",
        "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
        "#count_vect  = CountVectorizer(analyzer=clean_text)\n",
        "#X_tfidf = count_vect.fit_transform(data['body_text'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPta7SJq9kPC"
      },
      "source": [
        "##  create the feature matrix kept the label seperate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Or2csw47uVY"
      },
      "source": [
        "X_features = pd.concat([data['body_len'],data['punct%'],pd.DataFrame(X_tfidf.toarray())],axis= 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "ispbxiUz8o1X",
        "outputId": "6e644cb3-8233-4464-a4f9-11b8453b1519"
      },
      "source": [
        "X_features.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>body_len</th>\n",
              "      <th>punct%</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>...</th>\n",
              "      <th>8067</th>\n",
              "      <th>8068</th>\n",
              "      <th>8069</th>\n",
              "      <th>8070</th>\n",
              "      <th>8071</th>\n",
              "      <th>8072</th>\n",
              "      <th>8073</th>\n",
              "      <th>8074</th>\n",
              "      <th>8075</th>\n",
              "      <th>8076</th>\n",
              "      <th>8077</th>\n",
              "      <th>8078</th>\n",
              "      <th>8079</th>\n",
              "      <th>8080</th>\n",
              "      <th>8081</th>\n",
              "      <th>8082</th>\n",
              "      <th>8083</th>\n",
              "      <th>8084</th>\n",
              "      <th>8085</th>\n",
              "      <th>8086</th>\n",
              "      <th>8087</th>\n",
              "      <th>8088</th>\n",
              "      <th>8089</th>\n",
              "      <th>8090</th>\n",
              "      <th>8091</th>\n",
              "      <th>8092</th>\n",
              "      <th>8093</th>\n",
              "      <th>8094</th>\n",
              "      <th>8095</th>\n",
              "      <th>8096</th>\n",
              "      <th>8097</th>\n",
              "      <th>8098</th>\n",
              "      <th>8099</th>\n",
              "      <th>8100</th>\n",
              "      <th>8101</th>\n",
              "      <th>8102</th>\n",
              "      <th>8103</th>\n",
              "      <th>8104</th>\n",
              "      <th>8105</th>\n",
              "      <th>8106</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>160</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>128</td>\n",
              "      <td>4.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49</td>\n",
              "      <td>4.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>7.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 8109 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   body_len  punct%    0    1    2    3  ...  8101  8102  8103  8104  8105  8106\n",
              "0       160     2.5  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "1       128     4.7  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "2        49     4.1  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "3        62     3.2  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "4        28     7.1  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
              "\n",
              "[5 rows x 8109 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7s-hMja_OUk"
      },
      "source": [
        "## Explore Random Forest using Cross- Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk4hH1nO8qJF"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold, cross_val_score"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QZusHRB_UWD",
        "outputId": "c0da99d4-118b-410f-959a-f27df21a3b2f"
      },
      "source": [
        "rf = RandomForestClassifier(n_jobs=-1)# By setting the n_jobs =-1 it run faster \n",
        "k_fold = KFold(n_splits=5)\n",
        "cross_val_score(rf,X_features,data['labels'],cv = k_fold, scoring='accuracy',n_jobs = -1)\n",
        "#cross_val_score(rf(classifier),X_features(feature matrices),data['labels'](target),cv = k_fold, scoring='accuracy',n-jobs = -1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97576302, 0.97755835, 0.97396768, 0.9640611 , 0.97124888])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbsFTJ_ft6-9"
      },
      "source": [
        "## Random Forest with Hold-Out Testset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMgYhGm6ARcN"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as score \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7wzAToGvDzn"
      },
      "source": [
        "#Splitting the dataset into train and test\n",
        "X_train,X_test,y_train, y_test = train_test_split(X_features,data['labels'],test_size= 0.2)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjCwWzWdvUxv"
      },
      "source": [
        "#customiza the existing random forest classifier for the use\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=50,max_depth=20,n_jobs=-1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxvfGL9kwPeF"
      },
      "source": [
        "#Fit the rf model with the training data \n",
        "rf_model = rf.fit(X_train,y_train)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5E5oTO0wkbf",
        "outputId": "bda40068-fc39-41fb-8afc-fc9f028dd1bb"
      },
      "source": [
        "#Which features has the most importance in the random forest classifier\n",
        "sorted(zip(rf_model.feature_importances_, X_train.columns),reverse =True)[0:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.05711326526782927, 1804),\n",
              " (0.04193645939156851, 3135),\n",
              " (0.041837430441892226, 'body_len'),\n",
              " (0.03450783224274282, 7353),\n",
              " (0.024474614391816116, 4799),\n",
              " (0.021729050305971494, 2032),\n",
              " (0.01885797770017705, 6288),\n",
              " (0.01808435524543834, 5727),\n",
              " (0.013964538476929545, 2172),\n",
              " (0.013955988069124762, 7785)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzFWiDfAxlrr"
      },
      "source": [
        "y_pred = rf_model.predict(X_test)\n",
        "precision, recall,fscore, support = score(y_test,y_pred,pos_label='spam',average='binary')\n",
        "#precision, recall,fscore, support = score(y_test,y_pred,pos_label='ham',average='binary')\n",
        "#Based on the pos_label it will calculate the score "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtYJ_yKRw-hK",
        "outputId": "77d7d4f7-ce4a-4dc4-9cc9-949eed0a0ca9"
      },
      "source": [
        "print('precision: {} / Recall: {} / Accuracy: {}'.format(round(precision,3),round(recall,3),\n",
        "                                                         (y_pred == y_test).sum()/len(y_pred)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 1.0 / Recall: 0.618 / Accuracy: 0.947935368043088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ834W-wzAd7"
      },
      "source": [
        "\n",
        "\n",
        "1.   Precision: 1 ==>All mail in the spam folder is the spam\n",
        "2.   Recall ==> 61.8% of all spam that has come to your mailwas properly placed into the spam folder \n",
        "\n",
        "1.  Accuracy: ==>  95% of emails that comes into your mail that correctly identified as spam\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8FQTjtZz_nq"
      },
      "source": [
        "## Random Forest With Grid Search \n",
        "\n",
        "Exhaustively search all the parameter/hyper parameter combination in a given grid to determine the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDA5x-lky0Q7"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as score \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzZtcKFg0qY5"
      },
      "source": [
        "#Splitting the dataset into train and test\n",
        "X_train,X_test,y_train, y_test = train_test_split(X_features,data['labels'],test_size= 0.2)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoEgpO7w4z2o"
      },
      "source": [
        "def train_RF(n_est, depth):\n",
        "  rf = RandomForestClassifier(n_estimators=n_est, max_depth=depth, n_jobs=-1)\n",
        "  rf_model = rf.fit(X_train, y_train)\n",
        "  y_pred = rf_model.predict(X_test)\n",
        "  precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
        "  print('Est: {} / Depth: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
        "           n_est, depth, round(precision, 3), round(recall, 3),\n",
        "           round((y_pred==y_test).sum() / len(y_pred), 3)))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LERpaU8y38Pl",
        "outputId": "53d01635-f15e-4ee0-a25b-4111ad92544c"
      },
      "source": [
        "for n_est in [10, 50, 100]:\n",
        "    for depth in [10, 20, 30, None]:\n",
        "      train_RF(n_est, depth)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Est: 10 / Depth: 10 ---- Precision: 1.0 / Recall: 0.246 / Accuracy: 0.904\n",
            "Est: 10 / Depth: 20 ---- Precision: 1.0 / Recall: 0.585 / Accuracy: 0.947\n",
            "Est: 10 / Depth: 30 ---- Precision: 1.0 / Recall: 0.69 / Accuracy: 0.961\n",
            "Est: 10 / Depth: None ---- Precision: 1.0 / Recall: 0.831 / Accuracy: 0.978\n",
            "Est: 50 / Depth: 10 ---- Precision: 1.0 / Recall: 0.261 / Accuracy: 0.906\n",
            "Est: 50 / Depth: 20 ---- Precision: 1.0 / Recall: 0.634 / Accuracy: 0.953\n",
            "Est: 50 / Depth: 30 ---- Precision: 1.0 / Recall: 0.746 / Accuracy: 0.968\n",
            "Est: 50 / Depth: None ---- Precision: 1.0 / Recall: 0.845 / Accuracy: 0.98\n",
            "Est: 100 / Depth: 10 ---- Precision: 1.0 / Recall: 0.289 / Accuracy: 0.909\n",
            "Est: 100 / Depth: 20 ---- Precision: 1.0 / Recall: 0.669 / Accuracy: 0.958\n",
            "Est: 100 / Depth: 30 ---- Precision: 1.0 / Recall: 0.746 / Accuracy: 0.968\n",
            "Est: 100 / Depth: None ---- Precision: 1.0 / Recall: 0.831 / Accuracy: 0.978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpczxDTy5jIj"
      },
      "source": [
        "**Check with other hyperparameter for the best performance of random forest⚡**"
      ]
    }
  ]
}