{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dee25bd-9cef-4363-8ce2-2e8239b61385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec36e9a-9e72-4778-b939-d64ea95d2103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                          body_text\n",
       "0    ham  I've been searching for the right words to tha...\n",
       "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2    ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3    ham  Even my brother is not like to speak with me. ...\n",
       "4    ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\rajse\\OneDrive\\Desktop\\Ex_Files_NLP_Python_ML_EssT/SMSSpamCollection.tsv\",sep = '\\t', header = None)\n",
    "data.columns = ['labels', 'body_text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65af2e13-0c77-4c06-9a3f-6d378c7e417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rajse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd \n",
    "import re \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import string \n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps=nltk.PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd7a8360-896f-4f9a-b079-22f731dfd091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of character = len(string)- count of white-spaces\n",
    "data['body_len']=data['body_text'].apply(lambda x :len(x)-x.count(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3735de17-a225-40ad-8637-9a4f5522f803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                          body_text  body_len  punct%\n",
       "0    ham  I've been searching for the right words to tha...       160     2.5\n",
       "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...       128     4.7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Creating a function to fin dout the % of punctuation present in the text\n",
    "def count_punct(text):\n",
    "  count = sum([1 for char in text if char in string.punctuation])\n",
    "  return round(count/(len(text) - text.count(\" \")), 3)*100\n",
    "    \n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065ad8fb-c638-4879-ba08-295007d73b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  text = \"\".join([word.lower() for word in text if word not in string.punctuation])#Punctuation removal\n",
    "  tokens = re.split('\\W+', text) #tokenize\n",
    "  text = [ps.stem(word) for word in tokens if word not in stopwords] # Stopwords removal\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de84bf4-3204-4177-a0f9-ff686e2f2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect  = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "#count_vect  = CountVectorizer(analyzer=clean_text)\n",
    "#X_tfidf = count_vect.fit_transform(data['body_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a9e00b6-f84f-4014-acb5-7770351708c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = pd.concat([data['body_len'],data['punct%'],pd.DataFrame(X_tfidf.toarray())],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "731cf7ce-a469-4b3c-b4a9-a17d615cac4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8097</th>\n",
       "      <th>8098</th>\n",
       "      <th>8099</th>\n",
       "      <th>8100</th>\n",
       "      <th>8101</th>\n",
       "      <th>8102</th>\n",
       "      <th>8103</th>\n",
       "      <th>8104</th>\n",
       "      <th>8105</th>\n",
       "      <th>8106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 8109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%    0    1    2    3    4    5    6    7  ...  8097  8098  \\\n",
       "0       160     2.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1       128     4.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "   8099  8100  8101  8102  8103  8104  8105  8106  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[2 rows x 8109 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918d36cf-c64d-4d14-93a7-bb4b12ab341f",
   "metadata": {},
   "source": [
    " Explore  Gradient-Boosting Classifier Attributes & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "228197ad-ec32-46cb-9139-f5bb0f692753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_SUPPORTED_LOSS', '__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_check_initialized', '_check_n_features', '_check_params', '_clear_state', '_compute_partial_dependence_recursion', '_estimator_type', '_fit_stage', '_fit_stages', '_get_param_names', '_get_tags', '_init_state', '_is_initialized', '_make_estimator', '_more_tags', '_raw_predict', '_raw_predict_init', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_required_parameters', '_resize_state', '_staged_raw_predict', '_validate_data', '_validate_estimator', '_validate_y', '_warn_mae_for_criterion', 'apply', 'decision_function', 'feature_importances_', 'fit', 'get_params', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params', 'staged_decision_function', 'staged_predict', 'staged_predict_proba']\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "print(dir(GradientBoostingClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a21bde67-8691-4d4b-80dd-968fd73e7d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "766541e8-d827-4280-8a90-2b6832b9a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_features,data['labels'],test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "417f3e38-ad58-4378-9d27-50485348ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GB(est, max_depth, lr):\n",
    "        gb = GradientBoostingClassifier(n_estimators=est, max_depth=max_depth, learning_rate=lr)\n",
    "        gb_model = gb.fit(X_train, y_train)\n",
    "        y_pred = gb_model.predict(X_test)\n",
    "        precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "        print('Est: {} / Depth: {} / LR: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "                                                                                est, max_depth, lr, round(precision, 3), round(recall, 3),\n",
    "                                                                                round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef4f5848-681e-40d2-bf48-24f89831dcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 50 / Depth: 3 / LR: 0.01 ---- Precision: 0.0 / Recall: 0.0 / Accuracy: 0.87\n",
      "Est: 50 / Depth: 3 / LR: 0.1 ---- Precision: 0.938 / Recall: 0.731 / Accuracy: 0.959\n",
      "Est: 50 / Depth: 3 / LR: 1 ---- Precision: 0.886 / Recall: 0.807 / Accuracy: 0.961\n",
      "Est: 50 / Depth: 7 / LR: 0.01 ---- Precision: 1.0 / Recall: 0.007 / Accuracy: 0.871\n",
      "Est: 50 / Depth: 7 / LR: 0.1 ---- Precision: 0.931 / Recall: 0.834 / Accuracy: 0.97\n",
      "Est: 50 / Depth: 7 / LR: 1 ---- Precision: 0.904 / Recall: 0.841 / Accuracy: 0.968\n",
      "Est: 50 / Depth: 11 / LR: 0.01 ---- Precision: 1.0 / Recall: 0.014 / Accuracy: 0.872\n",
      "Est: 50 / Depth: 11 / LR: 0.1 ---- Precision: 0.916 / Recall: 0.828 / Accuracy: 0.968\n",
      "Est: 50 / Depth: 11 / LR: 1 ---- Precision: 0.922 / Recall: 0.821 / Accuracy: 0.968\n",
      "Est: 50 / Depth: 15 / LR: 0.01 ---- Precision: 1.0 / Recall: 0.007 / Accuracy: 0.871\n",
      "Est: 50 / Depth: 15 / LR: 0.1 ---- Precision: 0.938 / Recall: 0.828 / Accuracy: 0.97\n",
      "Est: 50 / Depth: 15 / LR: 1 ---- Precision: 0.909 / Recall: 0.828 / Accuracy: 0.967\n"
     ]
    }
   ],
   "source": [
    "for n_est in [50]:\n",
    "       for max_depth in [3, 7, 11, 15]:\n",
    "            for lr in [0.01, 0.1, 1]:\n",
    "                train_GB(n_est, max_depth, lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec895b-4c24-4072-95ca-e4b6a1789b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
